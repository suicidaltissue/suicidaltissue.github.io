---
type: Lecture Notes
panopto: https://aberystwyth.cloud.panopto.eu/Panopto/Pages/Viewer.aspx?id=cc514807-c632-4901-8a7d-b13000c8d6e1
lecturer: Amanda Clare
slides: https://blackboard.aber.ac.uk/ultra/courses/_46446_1/outline/edit/document/_2753956_1?courseId=_46446_1&view=content
notesCompleted: true
dateCompleted: 2024-04-13
module:
---
# Distributions
How can we use this kind of information to determine if the data obtained from an experiment is important, unusual or expected by chance anyway?

We will also look at generating randomly distributed data from probability distributions

## Probability
A Probability is measured from a scale 0 - 1

###  Flipping Coins (Most Basic Example)
The classic example of tossing a coin. There is a specific language that is used to describe probability.
`P(X = HEADS)` : the outcome is HEADS
`P(X = TAILS)` : the outcome is TAILS

then to describe the probability of X being HEADS you can use  `P(X = HEADS)` or `P(X=TAILS)` sometimes there may be a small r by P to represent Probability for example `Pr(X - HEADS)`

with a fair coin the probability would be 
`P(HEADS)=0.5` or `P(TAILS)=0.5`

## Uniform Distribution
Lets look at National Lottery Balls, specifically the frequency of which a specific ball is chosen.

![[Pasted image 20240403135313.png]]

in this case we are looking at 10000 draws, each number is equally likely to occur, this is what is called Uniform Distribution. as you can see the above graph has some variation, the more draws we look at the more even the graph will look.

if we re-scale the Y axis to be real probability instead of counts we can determine that the probability of each ball being drawn is 0.0169  = 1/59 this is represented with the red line and as you can see each ball falls roughly there

![[Pasted image 20240404100126.png]]

```python
bonus_balls = rng.integers(1, 60, 10000)
unique, counts = np.unqiue(bonus_balls, return_counts=True)
plt.bar(unique, counts)
```

## Binomial Distribution

### Multiple Flips
lets look at an experiment in which we flip n coins at the same time. In this case n = 5, each coin is fair so they have 1/2 probability of landing on each side.

there are a number of different possibilities of the outcome of these 5 flips, for example
- TTTTT
- HTTTT
- TTTTT

so knowing this how likely are we to get 3 heads in 10 trials ( 10 x 5 flips) ? this can be found by using [Binomial Probability Distribution] we can also do this using probabilities other than 0.5, for example the probability of rolling a 6 on a 6 sided die

```python
from scipy import stats
stas.binom.rvs(n, p, size)
```

- **n:** Number of flips per trial
- **p:** Success probability
- **size:** number of trials

using `stats.binom.rvs(5,0.5,10)` will generate a list  for example `[3,4,1,3,4,1,5,2,1,3]` each element in the list represents one trial and gives you the number of successes in that trial.

you can also do this with just one event. For example flipping a single coin 10 times

```python
stats.binom.rvs(1, 0.5, 10)
```

### Galton Board
![[Pasted image 20240405111209.png]]
If you drop a bell down this Galton Board, it will bounce of each peg either left or right, as it goes down the board a seemingly random bin is allocated depending on the outcome of the ball bouncing on these pegs, this is subject to Binomial Distribution. 

#### Continuous Probability Distribution
There is an example video showing this with more balls and bins, as they balls fall it seems like complete chaos but by the end they are all sorted to a Binomial Distrbution
````col
```col-md
flexGrow=1
===
![[Pasted image 20240413132925.png]]
```
```col-md
flexGrow=1
===
![[Pasted image 20240413132942.png]]
```
````
The Larger the number of bins the lower the probability of any one ball landing in a specific bin, for example if we have 10 to the power of 10 bins the probability would be 0

## Many Trials
lets say we want to do 10000 trials of 5 coin flips and we want to plot the total number of heads using a [[10. Plotting#Bar Charts| Bar Chart]]

```python
fair_coin_flips = stats.binom.rvs(n=5, p=0.5, size=10000)
unique, counts = np.unique(fair_coin_flips, return_counts=True)
plt.bar(unique, counts/1000)
```

![[Pasted image 20240404122409.png]]

## Probability Mass Function
Is used to get the probability of getting exactly a particular outcome. For example for a 5 coin flip how probable is it to get exactly 3 Heads? This is written in probability language

```
pmf (0) = P(no heads)
pmf (1) = P(1 head)
pmf (2) = P(2 heads)
pmf (3) = P(3 heads)
pmf (4) = P(4 heads)
pmf (5) = P(5 heads)
```

the `stats.binom.pmf(k, n, p)` allows us to do this with
- k: kth outcome (number of successes for binomial)
- n: number of flips per trial
- p: success probability

so to test the probability of getting different numbers of heads you simply change the k variable. This can be printed using a list comprehension to show the probabilities of 0-5

```python
[stats.binom.pmf(k,5,0.5) for k in range(6)]
```

```
[0.03125 , 0.15625 , 0.3125 , 0.3125 , 0.15625 , 0.03125]
```

## Cumulative Density
Lets say we want to figure out the probability of getting a particular outcome or less than that outcome, for example we want to determine weather a bee visited generally less than 4 blue flowers, this is done with `stats.binom.cdf`
in probability language it is written like

```
cdf(0) = P(no heads)
cdf(0) = P(no heads)
cdf(0) = P(no heads)
cdf(0) = P(no heads)
cdf(0) = P(no heads)
cdf(0) = P(no heads)
```

The Python Function for this takes the same 3 parameters discussed for the [[#Probability Mass Function]] K,N and P

## Normal distribution
It is also commonly known as a Gaussian distrtibution.

A Normal Distribution is a continuous probability distribution of floating point values that is very commonly observed. For data to be considered of normal distribution, majority of the data will fall in the middle of the graph (the mean) and the rest falls on two standard deviations.

![[Pasted image 20240408100802.png]]

there are different methods to test weather data is of normal distribution.

Often when describing a dataset is of normal distribution someone will describe it using words, but it can also be seen described using maths, this would look like

```
X ∼ N(μ, σ2)
```

### Standard Normal (38:00)
If you have data that is distributed according to a normal distribution, you can standardise it to allow you to use lookup tables. 
Before the age of computers this is exactly what they would do, this means that when a analyist found out their data was normally distributed they would then be able to look it up in a book, this worked by having a standard normal distribution.

- [ ] #todo Add More Details To Standard Normal Notes

#### Example: Mean 0, Std Deviation 1
```python
mean = 400
stddev = 80

vals = rng.normal(loc=mean, scale=stddev, size=10000)
smpmean = np.mean(vals)
smpstd = np.std(vals)

standardised_vals = (vals - mean) / std
z_mean = np.mean(standardised_vals)
z_std = np.std(standardised_vals)

```

When converting the vals data to standardised vals, we use [[Vectorised Operations]] which applys the operation to every element in the array, in this case the mean is subtracted from every element in vals.

#### Try It
Generate 10 Random Numbers
- Subject To Standard Normal Distribution
	- Mean 1
	- Deviation 0
- Subject To Normal Distrbution
	- Mean 10
	- Deviation 10
- Calculate the mean and standard deviation for each of the arrays

```python
def generate_numbers(mean, deviation):
	rng = np.random.default_rng(74587)
	stats.norm.random_state = rng
	vals = stats.norm.rvs(loc=mean, scale=deviation, size=10)
	smplmean = np.mean(vals)
	smpldeviation = np.std(vals)
	return (smplmean, smplydeviation)

print("Standard Normal Distribution: ")
generate_numbers(0,1)

print("Normal Distrbution: ")
generate_numbers(10, 10)

```

### Cumulative Probability (CDF)
![[Pasted image 20240413150255.png]]
Lets look at an example using Plant Heights. Miscanthus plants are often used for bio fuel and reach up to 3m tall when fully grown.

- Lets say That Miscanthus Plant Heights are [[#Normal distribution|Normally Distributed]] (Shown Above)
	- Mean 1.70m
	- Standard Deviation 0.1
- The Graph on the right shows the Cummulative Probability `CDF(1.65, 1.70, 0.1)` represents the probability that a plants height is  no more than 1.65m
	- At the bottom of the graph, you can see it shows that its not very likely that the plants height is no more than 1.4
	- At the middle of the graph (The mean) you can see it is 50% likely that the plant is 1.7 or less
	- And by the time you get to the top, 100% of the plants are 1.9 or less

This allows us to determine whether the data we have is unusual or what we expect.

we can also look at it like this, the CDF Highlighted in green shows that the probability of it being within this range, you are also able to calculuate the probability of it being more than the given value by subtracting the CDF from 1 (with 1 representing a whole)
![[Pasted image 20240409142549.png]]

#### Try It
Calculate the probability of the following
- Height < 1.50
	- `stats.norm.cdf(1.5, 1.7, 0.1)`
		- 
- Height < 1.90
	- `stats.norm.cdf(1.9, 1.7, 0.1)`
		- 
- Height Between 1.90 - 1.50
	- `stats.norm.cdf(1.9, 1.7, 0.1) - stats.norm.cdf(1.5, 1.7, 0.1)`
		- 

- [ ] #todo Generate Answers For CDF Try It!


#lecturenote
