---
type: Lecture Notes
panopto: https://ultra.content.blackboardcdn.com/ultra/uiv3900.89.0-rel.24_a040267#
lecturer: 
slides: https://blackboard.aber.ac.uk/ultra/courses/_46446_1/outline/edit/document/_2757300_1?courseId=_46446_1&view=content
notesCompleted: true
dateCompleted: 
module:
---
# Correlation
is used to reference a statistical relationship between variables.

## Correlation Types

````col
```col-md
flexGrow=1
===
# Uncorrelated
![[Pasted image 20240506214009.png]]
```
```col-md
flexGrow=1
===
# Postively
![[Pasted image 20240506214016.png]]
```
```col-md
flexGrow=1
===
# Negatively
![[Pasted image 20240506214022.png]]
```
````


## Variance
The variance is used to measure how widely things are dispersed from their mean
it is often quoted with the mean and can be calculated in python with
- `statistics.variance(x)`
- `numpy.var(x, ddof=1)`

So for each datapoint we take the difference from the mean then we square that in order to get a positive value. We then add all these together and divide by the number of data points.

### Example
```python
x = [1,2,3,4,5]
y = [10,8,6,4,2]
print(statistics.variance(x))
print(statistics.variance(y))
```

## Covariance
The joint variability of two variables or data points
- `statistics.covariance(x, y)`
- `np.cov(two_row_array)`
### Example
```python
x = [1,2,3,4,5]
y = [10,8,6,4,2]
print(statistics.covariance(x, y))
print(statistics.covariance(y, x))
```

## Pearson's Correlation CoEfficient
A Normalised Measurement of the covariance so that the result always
has a value between **-1 and 1** 

- `numpy.corrcoeff(x,y)`
- `scipy.stats.pearsonr(x,y)`
- `statistics.correlation(x,y)`

### Example
```python
statistics.correlation(x,y)
```

## Simpsons Paradox
Before we run any correlation calculations we need to make sure that the data is definitely correlated in the way we think. There is a phenomenon called Simpsons Paradox which refers to when data appears to be correlated but when you group the data it can show a different type of correlation

````col
```col-md
flexGrow=1
===
# Column 0
![[Pasted image 20240506214044.png]]
```
```col-md
flexGrow=1
===
# Column 1
![[Pasted image 20240506214050.png]]
```
```col-md
flexGrow=1
===
# Column 2
![[Pasted image 20240506214056.png]]
```
````

as you can see the first plot shows that the data has a negative correlation however if you look at the data in 5 groups then you can see that it actually has a positive correlation

## Anscombe's Quarter
Lets look at 4 pairs of `x,y` data for each pair you must calculate
- mean of both axis
- sample variance of both axis
- correlation of both axis

### Example
```python

```

## Correlation and Causation
![[Pasted image 20240511151903.png]]

#lecturenote
